---

<h1 align="center">ğŸ§ ğŸ”§ Basic RAG Implementations</h1>

<p align="center">
  <img src="https://img.shields.io/badge/Groq-Inference%20API-blueviolet?style=flat-square" />
  <img src="https://img.shields.io/badge/Ollama-GGUF%20Models-success?style=flat-square" />
  <img src="https://img.shields.io/badge/HuggingFace-Transformers-orange?style=flat-square" />
  <img src="https://img.shields.io/badge/OpenAI-ChatGPT%20API-9cf?style=flat-square" />
  <img src="https://img.shields.io/badge/Notebook-Examples-informational?style=flat-square" />
</p>

---

## ğŸ“˜ Overview

**Basic_RAGs** is a notebook suite showcasing how to build minimal RAG pipelines using different **LLM providers** â€” like Groq, HuggingFace, Ollama, and OpenAI.  
It is the **next step after** [`RAG_pipline_fundamentals`](../RAG_pipline_fundamentals), where core concepts like **Ingestion**, **Retrieval**, and **Synthesis (Generation)** were explained.

This module helps you compare how different APIs and inference providers affect your RAG pipelineâ€™s performance and behavior.

---

## ğŸ§± Folder Structure

```bash
Basic_RAGs/
â”œâ”€â”€ .env                            # Local secrets (ignored by git)
â”œâ”€â”€ .env.example                    # Environment template for API keys
â”œâ”€â”€ .gitignore                      # Ignore .env and cache files
â”œâ”€â”€ basic_rag_using_groq_api.ipynb         # RAG using Groq API (LLaMA-3)
â”œâ”€â”€ basic_rag_using_huggingface.ipynb      # RAG using Hugging Face models
â”œâ”€â”€ basic_rag_using_ollama.ipynb           # Local LLM RAG using Ollama
â”œâ”€â”€ basic_rag_using_openai.ipynb           # RAG using OpenAI (GPT-3.5/4)
â”œâ”€â”€ basic_rag_using_openai_og.ipynb        # Legacy/fallback OpenAI flow
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ sample.pdf                     # Example input document
```

---

## ğŸš€ How It Works

Each notebook follows the same basic flow:

### 1. ğŸ§© Ingestion  
- Load documents (PDF)  
- Chunk them into overlapping text segments  
- Generate embeddings using chosen model  

### 2. ğŸ” Retrieval  
- Convert user query into embedding  
- Search top-K matching document chunks  
- Return context  

### 3. ğŸ§  Synthesis (Generation)  
- Format prompt with query + context  
- Generate answer using selected LLM backend  

---

## ğŸ”„ RAG Workflow (Simplified View)

```mermaid
graph TD
    A[Document Ingestion] --> B[Semantic Retrieval]
    B --> C[Context-Aware Response Generation]
```

---

## ğŸ““ Notebook Breakdown

| Notebook | Backend | Highlights |
|----------|---------|------------|
| `basic_rag_using_groq_api.ipynb` | ğŸŸ£ **Groq** | Uses Groq Cloud's ultra-fast LLaMA-3-70B |
| `basic_rag_using_huggingface.ipynb` | ğŸŸ  **HuggingFace** | Local/API-hosted transformer models |
| `basic_rag_using_ollama.ipynb` | ğŸŸ¢ **Ollama** | Run quantized GGUF models locally |
| `basic_rag_using_openai.ipynb` | ğŸ”µ **OpenAI** | GPT-3.5, GPT-4, and instruction tuning |
| `basic_rag_using_openai_og.ipynb` | ğŸ”µ **OpenAI (Legacy)** | Older OpenAI-style generation setup |

---

## âš™ï¸ Setup Instructions

### âœ… Step 1: Install dependencies

```bash
pip install -r requirements.txt
```

### âœ… Step 2: Configure environment variables

```bash
cp .env.example .env
```

Then fill in your API keys for:
- OpenAI
- Hugging Face
- Groq
- Ollama (if local)

> `.env` is already in `.gitignore`, so you're safe from leaking credentials.

---

## ğŸ“„ Sample Use Case

Use `sample.pdf` or your own documents to:
- Perform PDF-to-knowledge RAG
- Compare inference latency and output quality
- Switch between providers with minimal code changes

---

## ğŸ§  What You'll Learn

- Differences in LLM behavior across Groq, OpenAI, HF, and Ollama
- How to plug various LLM APIs into the same RAG framework
- How quantized local models compare to cloud-hosted ones

---

## ğŸ§µ Inspired By

- [RAG: Retrieval-Augmented Generation (Meta)](https://arxiv.org/pdf/2005.11401.pdf)
- [OpenAI API](https://platform.openai.com/)
- [Hugging Face Transformers](https://huggingface.co/)
- [GroqCloud](https://console.groq.com/)
- [Ollama](https://ollama.com/)

---

## ğŸ¤ Contributing

Feel free to submit PRs, bug reports, or ideas!  
This repo is designed as a flexible **learning-first sandbox** ğŸ”¬

---

## ğŸ§‘â€ğŸ’» Author

**Chirag Bansal**

ğŸ”— [LinkedIn](https://www.linkedin.com/in/chiragb254)  
ğŸ¦ [Twitter/X](https://twitter.com/ChiragB254)  
ğŸ“ [Medium](https://medium.com/@ChiragB254)  
ğŸ“· [Instagram](https://instagram.com/data.scientist_chirag)  
ğŸ“§ [Email](mailto:devchirag27@gmail.com)  
ğŸ’» [GitHub](https://github.com/ChiragB254)

---

<p align="center" style="font-size: 13px; color: black; font-style: italic;">
  <strong>Made with â¤ï¸ by Chirag Bansal</strong> for the open-source AI community.
</p>