{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "961003a4",
   "metadata": {},
   "source": [
    "# üß† RAG with Question Transformation (Step-Back Strategy)\n",
    "\n",
    "This notebook demonstrates how to build a smarter RAG (Retrieval-Augmented Generation) system using a method called **\"Step-Back Questioning\"**.\n",
    "\n",
    "---\n",
    "\n",
    "## ü§î What is RAG?\n",
    "\n",
    "RAG stands for **Retrieval-Augmented Generation**. It combines:\n",
    "- **Search**: Looks up useful info from documents\n",
    "- **AI Answering**: Uses a language model to write an answer based on that info\n",
    "\n",
    "It helps answer questions even if the model doesn't \"know\" the answer itself.\n",
    "\n",
    "---\n",
    "\n",
    "## ü™ú What's Step-Back Questioning?\n",
    "\n",
    "Sometimes user questions are too detailed or tricky for the system to retrieve the right content.  \n",
    "So we apply a **Step-Back** method to turn a complex question into a **more general or easier one** first.\n",
    "\n",
    "For example:\n",
    "> Original Question: *Could the members of The Police perform lawful arrests?*  \n",
    "> Step-Back Version: *What can the members of The Police do?*\n",
    "\n",
    "This **simpler version** helps fetch better, more useful information ‚Äî which can then be used to answer the original question more accurately.\n",
    "\n",
    "---\n",
    "\n",
    "## üìö What This Notebook Does\n",
    "\n",
    "### 1. Load Documents\n",
    "We start by reading a PDF document and splitting it into smaller parts (called \"chunks\").\n",
    "\n",
    "### 2. Build Step-Back Prompt\n",
    "We design a special prompt with **examples** to teach the AI how to turn a detailed question into a general one.\n",
    "\n",
    "### 3. Generate a Step-Back Question\n",
    "We use the LLM to generate a new, broader question based on the original.\n",
    "\n",
    "### 4. Retrieve and Generate\n",
    "- Use the **step-back question** to search for relevant chunks\n",
    "- Feed the found chunks along with the **original question** into the AI\n",
    "- Get a smart, context-aware answer\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Why Use Step-Back Questioning?\n",
    "\n",
    "- Helps find better context from documents\n",
    "- Makes it easier for the AI to understand and answer\n",
    "- Especially useful when the original question is unusual or very specific\n",
    "\n",
    "---\n",
    "\n",
    "> This is a great intro to advanced prompting techniques for Retrieval + LLMs.  \n",
    "> You're teaching the AI not just *how to answer*, but also *how to ask better questions*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58127c6",
   "metadata": {},
   "source": [
    "## üì¶ Import Required Libraries\n",
    "\n",
    "This cell loads all the necessary tools including document loaders, prompt templates, LLMs, embeddings, and vector stores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d015736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LangChain components for vector search, PDF loading, prompts, etc.\n",
    "# Also load custom embedding and LLM wrappers defined in local files\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from llm_call import LLMCall\n",
    "from embeddings import Embeddings\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d264c1",
   "metadata": {},
   "source": [
    "## üìÑ Load and Split PDF Document\n",
    "\n",
    "We load a sample PDF file and split it into chunks using a text splitter.  \n",
    "This allows the retriever to work with smaller pieces of text and return more accurate results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7bc318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chirag/miniconda3/envs/LLMs-env/lib/python3.10/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "# Load the PDF document\n",
    "# Split it into overlapping text chunks to improve retrieval performance\n",
    "pdf_file = 'sample.pdf'\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 200\n",
    "\n",
    "loader = PyPDFLoader(pdf_file)\n",
    "documents = loader.load()\n",
    "\n",
    "# Split the document into manageable chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    ")\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da153cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.3 (Macintosh)', 'creationdate': '2024-06-18T14:09:48-07:00', 'moddate': '2024-06-18T14:10:14-07:00', 'trapped': '/False', 'source': 'sample.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='Before using iPhone, review the iPhone User Guide  at  \\nsupport.apple.com/guide/iphone .\\nSafety and Handling\\nSee ‚ÄúSafety, handling, and support‚Äù in the iPhone  \\nUser Guide .\\nExposure to Radio Frequency\\nOn iPhone, go to Settings > General > Legal &  \\nRegulatory > RF Exposure. Or go to apple.com/  \\nlegal/rfexposure .\\nBattery and Charging\\nAn iPhone battery should only be repaired by a trained \\ntechnician to avoid battery damage, which could cause \\noverheating, fire, or injury. Batteries should be recycled \\nor disposed of separately from household waste and \\naccording to local environmental laws and guidelines. For \\ninformation about Apple lithium-ion batteries and battery \\nservice and recycling, go to apple.com/batteries/service-\\nand-recycling . For information about charging, see \\n‚ÄúImportant safety information‚Äù in the iPhone User Guide.\\nLasers\\nThe proximity sensor, the TrueDepth camera system, \\nand the LiDAR Scanner contain one or more lasers.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first text chunk to inspect what the document looks like after splitting\n",
    "\n",
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93ba1977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many chunks were generated from the document\n",
    "\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3801752a",
   "metadata": {},
   "source": [
    "## üß† Define Step-Back Prompt\n",
    "\n",
    "We build a **few-shot prompt** that helps the LLM learn how to turn specific questions into simpler, broader versions.\n",
    "This \"step-back\" strategy boosts the effectiveness of document retrieval and generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deecfaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define few-shot examples to guide the LLM on how to reframe questions\n",
    "# These examples show how to turn complex or niche questions into simpler/general ones\n",
    "# Then, combine them into a full prompt that includes instructions + examples + actual input\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "\t\"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"what can the members of The Police do?\",\n",
    "    },\n",
    "    {\n",
    "\t\"input\": \"Jan Sindel‚Äôs was born in what country?\",\n",
    "        \"output\": \"what is Jan Sindel‚Äôs personal history?\",\n",
    "    },\n",
    "]\t\t\n",
    "\n",
    "# We now transform these to example messages\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\"human\", \"{input}\"),\n",
    "\t\t(\"ai\", \"{output}\"),\n",
    "\t]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "\texample_prompt=example_prompt,\n",
    "\texamples=examples,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\"system\", \n",
    "   \t\t\"\"\"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:\"\"\",),\n",
    "\n",
    "\t\t# Few shot examples\n",
    "\t\tfew_shot_prompt,\n",
    "\n",
    "\t\t# New questions\n",
    "\t\t(\"user\", \"{question}\"),\n",
    "\t]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168cd3eb",
   "metadata": {},
   "source": [
    "# Testing the Step Back Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "437ee54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generatye_queries_step_back = prompt | LLMCall.azure_openai() | StrOutputParser()\n",
    "\n",
    "question = \"Is there a warranty on the phone?\"\n",
    "queries = generatye_queries_step_back.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da4fd5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"what are the terms of the phone's warranty?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56efc38",
   "metadata": {},
   "source": [
    "## üí¨ Define Final RAG Prompt\n",
    "\n",
    "This prompt is used for the last step ‚Äî generating a detailed answer using the retrieved chunks and the original question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template for final answer generation\n",
    "# This will use retrieved context + original question to guide the LLM in producing an answer\n",
    "\n",
    "final_rag_template = \"\"\"\n",
    "You are a customer service agent for a apple mobile company. \n",
    "You have been given the following information about the customer question and the context.\n",
    "Normal Context = {context}\n",
    "Step Back Context = {step_back_context}\n",
    "Customer Query: {question}\n",
    "\n",
    "Answer: \n",
    "The answer should be based on the context provided.\n",
    "Your task is to answer the customer question based on the context provided. If the question is not related to the context, please say \"I don't know or Do Not Answer it just say please ask me question related to Apple Mobiles only\".\n",
    "Do not make up any information or provide any personal opinions or experiences.\n",
    "Please answer in a friendly and professional manner.\n",
    "\"\"\"\n",
    "\n",
    "# üìù Define the final RAG prompt template\n",
    "final_rag_prompt = ChatPromptTemplate.from_template(final_rag_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33e78ed",
   "metadata": {},
   "source": [
    "## üß™ Run the Full Step-Back RAG Pipeline\n",
    "\n",
    "This is where everything comes together:\n",
    "- Generate a general version of the question\n",
    "- Retrieve relevant content\n",
    "- Answer the original question using the found context\n",
    "\n",
    "\n",
    "> 1. Generate a step-back (simpler) question from the original\n",
    "> 2. Use the step-back version to retrieve better-matching documents\n",
    "> 3. Feed retrieved documents + original question to LLM to generate an answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f9bb0",
   "metadata": {},
   "source": [
    "## ‚òÅÔ∏è Using Azure OpenAI for Embeddings & Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "421828c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, there is a warranty on the phone. Apple offers a One-Year Limited Warranty that covers defects in materials and workmanship for one year from the date of original retail purchase. However, it does not cover normal wear and tear or damage caused by accident or abuse. To obtain service under this warranty, you can call Apple or visit an Apple Store or an Apple Authorized Service Provider. Please keep in mind that available service options may depend on the country where service is requested. If you have any more questions about the warranty or need assistance, feel free to ask!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üß† Initialize Azure OpenAI Embeddings\n",
    "open_ai_embeddings = Embeddings.azure_openai()\n",
    "\n",
    "vectorstore_openai = FAISS.from_documents(\n",
    "    texts,\n",
    "    open_ai_embeddings\n",
    ")\n",
    "\n",
    "retriever = vectorstore_openai.as_retriever()\n",
    "\n",
    "# ü§ñ Initialize Azure OpenAI Chat Model (LLM)\n",
    "open_ai_llm = LLMCall.azure_openai()\n",
    "\n",
    "chain = (\n",
    "\t{\n",
    "\t\t\"context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
    "        \"step_back_context\": generatye_queries_step_back | retriever,\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | final_rag_prompt | open_ai_llm | StrOutputParser()\n",
    "\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": question})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07293f0",
   "metadata": {},
   "source": [
    "## ü§ó Using Hugging Face for Embeddings & Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f20e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, there is a warranty on the phone. Apple offers a One-Year Limited Warranty that covers defects in materials and workmanship for one year from the date of original retail purchase. However, it does not cover normal wear and tear or damage caused by accident or abuse. To obtain service under this warranty, you can call Apple or visit an Apple Store or an Apple Authorized Service Provider. Please note that available service options may depend on your location. For more detailed information, you can visit apple.com/legal/warranty.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_embeddings = Embeddings.huggingface()\n",
    "\n",
    "vectorstore_hf = FAISS.from_documents(\n",
    "    texts,\n",
    "    huggingface_embeddings)\n",
    "\n",
    "retriever_hf = vectorstore_hf.as_retriever()\n",
    "\n",
    "huggingface_llm = LLMCall.huggingface()\n",
    "chain_hf = (\n",
    "    {\n",
    "\t\"context\": RunnableLambda(lambda x: x[\"question\"]) | retriever_hf,\n",
    "\t\"step_back_context\": generatye_queries_step_back | retriever_hf,\n",
    "\t\"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | final_rag_prompt | huggingface_llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain_hf.invoke({\"question\": question})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f509a9",
   "metadata": {},
   "source": [
    "## ü¶ô Using Ollama for Local LLM Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb0456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, there is a warranty on the phone. Apple offers a One-Year Limited Warranty that covers defects in materials and workmanship for one year from the date of original retail purchase. However, it does not cover normal wear and tear or damage caused by accident or abuse. If you need to obtain service under this warranty, you can call Apple or visit an Apple Store or an Apple Authorized Service Provider. For detailed information on obtaining service, you can visit apple.com/legal/warranty and support.apple.com.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama_llm = LLMCall.chat_ollama()\n",
    "\n",
    "vectorstore_ollama = FAISS.from_documents(\n",
    "    texts,\n",
    "    huggingface_embeddings)\n",
    "\n",
    "retriever_ollama = vectorstore_ollama.as_retriever()\n",
    "\n",
    "chain_ollama = (\n",
    "    {\n",
    "\t\"context\": RunnableLambda(lambda x: x[\"question\"]) | retriever_ollama,\n",
    "\t\"step_back_context\": generatye_queries_step_back | retriever_ollama,\n",
    "\t\"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | final_rag_prompt | ollama_llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain_ollama.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee52ccf5",
   "metadata": {},
   "source": [
    "## ‚ö° Using Groq Inference API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3f74e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, Apple provides a one-year limited warranty on its hardware products, including the iPhone, against defects in materials and workmanship. This warranty is valid for one year from the date of original retail purchase. You can find more information about the warranty and how to obtain service on Apple's website at apple.com/legal/warranty and support.apple.com.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_llm = LLMCall.chat_groq()\n",
    "\n",
    "vectorstore_groq = FAISS.from_documents(\n",
    "    texts,\n",
    "    open_ai_embeddings)\n",
    "\n",
    "retriever_groq = vectorstore_groq.as_retriever()\n",
    "\n",
    "chain_groq = (\n",
    "    {\n",
    "\t\"context\": RunnableLambda(lambda x: x[\"question\"]) | retriever_groq,\n",
    "\t\"step_back_context\": generatye_queries_step_back | retriever_groq,\n",
    "\t\"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | final_rag_prompt | groq_llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain_groq.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39661cca",
   "metadata": {},
   "source": [
    "<!-- Font Awesome CDN (Add in <head> if not already included) -->\n",
    "<link\n",
    "  rel=\"stylesheet\" \n",
    "  href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css\"\n",
    "/>\n",
    "\n",
    "<!-- Social Footer Section -->\n",
    "<div style=\"\n",
    "  background-color:rgb(199, 195, 195);\n",
    "  padding: 40px 30px;\n",
    "  border-radius: 20px;\n",
    "  box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
    "  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "  font-size: 18px;\n",
    "  max-width: 900px;\n",
    "  margin: 60px auto 30px;\n",
    "  text-align: center;\n",
    "  color: #444;\n",
    "\">\n",
    "<!-- End of Notebook Note -->\n",
    "  <h2 style=\"margin-bottom: 10px;\">üìò End of Notebook</h2>\n",
    "  <p style=\"color: #666; font-size: 14px;\">\n",
    "    Thank you for exploring! Feel free to connect via the links below.\n",
    "  </p>\n",
    "\n",
    "  <!-- Social Icons -->\n",
    "<div style=\"\n",
    "  display: flex;\n",
    "  gap: 25px;\n",
    "  align-items: center;\n",
    "  flex-wrap: wrap;\n",
    "  justify-content: center;\n",
    "  margin-bottom: 25px;\n",
    "\">\n",
    "  <!-- LinkedIn -->\n",
    "  <a href=\"https://www.linkedin.com/in/ChiragB254\" target=\"_blank\" style=\"text-decoration: none; color: #0077b5;\">\n",
    "    <i class=\"fab fa-linkedin fa-lg\"></i> LinkedIn\n",
    "  </a>\n",
    "\n",
    "  <!-- GitHub -->\n",
    "  <a href=\"https://github.com/ChiragB254\" target=\"_blank\" style=\"text-decoration: none; color: #333;\">\n",
    "    <i class=\"fab fa-github fa-lg\"></i> GitHub\n",
    "  </a>\n",
    "\n",
    "  <!-- Instagram -->\n",
    "  <a href=\"https://www.instagram.com/data.scientist_chirag\" target=\"_blank\" style=\"text-decoration: none; color: #E1306C;\">\n",
    "    <i class=\"fab fa-instagram fa-lg\"></i> Instagram\n",
    "  </a>\n",
    "\n",
    "  <!-- Email -->\n",
    "  <a href=\"mailto:devchirag27@gmail.com\" style=\"text-decoration: none; color: #D44638;\">\n",
    "    <i class=\"fas fa-envelope fa-lg\"></i> Email\n",
    "  </a>\n",
    "\n",
    "  <!-- X (Twitter) -->\n",
    "  <a href=\"https://x.com/ChiragB254\" target=\"_blank\" style=\"text-decoration: none; color: #000;\">\n",
    "    <i class=\"fab fa-x-twitter fa-lg\"></i> X.com\n",
    "  </a>\n",
    "  </div>\n",
    "\n",
    "  <p style=\"font-size: 13px; color: black; font-style: italic; margin-top: 8px;\">\n",
    "    <strong>Made with ‚ù§Ô∏è by Chirag Bansal</strong>\n",
    "  </p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
