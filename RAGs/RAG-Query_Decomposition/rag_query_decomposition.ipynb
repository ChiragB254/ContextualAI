{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de89e03d",
   "metadata": {},
   "source": [
    "# üîç RAG with Query Decomposition ‚Äì Simple Explanation\n",
    "\n",
    "This notebook shows how to build a **RAG (Retrieval-Augmented Generation)** system that uses a special trick called **query decomposition** to answer complex questions better.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† What's RAG?\n",
    "\n",
    "RAG means:\n",
    "1. Take a user question\n",
    "2. Search for relevant information (chunks) from documents\n",
    "3. Use a language model (like ChatGPT) to write an answer based on those documents\n",
    "\n",
    "This helps the model give better answers ‚Äî especially when it has limited memory and can't store all information.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© What is Query Decomposition?\n",
    "\n",
    "Sometimes, the question we ask is **too big** or **too complex** for the system to search properly. So, instead of using just the original question, we break it down into **smaller sub-questions**.\n",
    "\n",
    "For example:\n",
    "> **Original Question**: *How does Apple's iPhone differ from Samsung's latest phone in terms of camera and performance?*  \n",
    "> **Decomposed Queries**:  \n",
    "> - What is the camera quality of the iPhone?  \n",
    "> - What is the performance of the iPhone?  \n",
    "> - How does Samsung's latest phone camera compare?  \n",
    "> - What is the performance of Samsung's phone?\n",
    "\n",
    "By breaking things down, we can search **more effectively**, collect more useful info, and give **better answers**.\n",
    "\n",
    "---\n",
    "\n",
    "## üî® What This Notebook Does\n",
    "\n",
    "Here‚Äôs what happens step-by-step:\n",
    "\n",
    "1. **Load a PDF file** with content (for example, a manual, research doc, or article)\n",
    "2. **Split it into chunks** so it's easier to search\n",
    "3. Take the user's question and **break it into smaller questions** using an LLM (like GPT)\n",
    "4. Use each sub-question to search for relevant chunks\n",
    "5. **Combine** all the found chunks\n",
    "6. Feed everything to the language model to **generate a good answer**\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ñ LLMs and Embeddings Used\n",
    "\n",
    "- **Embeddings** (turn text into vectors): Hugging Face model `sentence-transformers/all-MiniLM-L6-v2`\n",
    "- **LLM for Decomposition and Answering**: Can be OpenAI, HuggingFace, Ollama, or Groq (you choose)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Why Use Query Decomposition?\n",
    "\n",
    "- Helps the system understand **complex or multi-part questions**\n",
    "- Increases the chance of finding **more relevant chunks**\n",
    "- Makes the final answer **more complete and accurate**\n",
    "\n",
    "---\n",
    "\n",
    "> This is a great starting point if you're learning about combining search + AI to build smarter systems!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c800915",
   "metadata": {},
   "source": [
    "******"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e5665",
   "metadata": {},
   "source": [
    "## üìö Importing Required Libraries\n",
    "\n",
    "We start by importing all the tools we need from LangChain and standard Python libraries.  \n",
    "These include document loaders, embedding models, LLM wrappers, and vector databases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e452d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from llm_call import LLMCall\n",
    "from embeddings import Embeddings\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e83153",
   "metadata": {},
   "source": [
    "## üìÑ Load and Prepare Documents\n",
    "\n",
    "We load a PDF file and break it into smaller overlapping text chunks using LangChain's text splitter.  \n",
    "This makes retrieval more accurate, especially for long documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ee4c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chirag/miniconda3/envs/LLMs-env/lib/python3.10/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "# Load PDF and split it into chunks\n",
    "pdf_file = 'sample.pdf'\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 200\n",
    "\n",
    "loader = PyPDFLoader(pdf_file)\n",
    "documents = loader.load()\n",
    "\n",
    "# Split the document into manageable chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    ")\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ee9418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.3 (Macintosh)', 'creationdate': '2024-06-18T14:09:48-07:00', 'moddate': '2024-06-18T14:10:14-07:00', 'trapped': '/False', 'source': 'sample.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='Before using iPhone, review the iPhone User Guide  at  \\nsupport.apple.com/guide/iphone .\\nSafety and Handling\\nSee ‚ÄúSafety, handling, and support‚Äù in the iPhone  \\nUser Guide .\\nExposure to Radio Frequency\\nOn iPhone, go to Settings > General > Legal &  \\nRegulatory > RF Exposure. Or go to apple.com/  \\nlegal/rfexposure .\\nBattery and Charging\\nAn iPhone battery should only be repaired by a trained \\ntechnician to avoid battery damage, which could cause \\noverheating, fire, or injury. Batteries should be recycled \\nor disposed of separately from household waste and \\naccording to local environmental laws and guidelines. For \\ninformation about Apple lithium-ion batteries and battery \\nservice and recycling, go to apple.com/batteries/service-\\nand-recycling . For information about charging, see \\n‚ÄúImportant safety information‚Äù in the iPhone User Guide.\\nLasers\\nThe proximity sensor, the TrueDepth camera system, \\nand the LiDAR Scanner contain one or more lasers.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first text chunk to inspect what the document looks like after splitting\n",
    "\n",
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340cac4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many chunks were generated from the document\n",
    "\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e831a",
   "metadata": {},
   "source": [
    "## üß† Query Decomposition Prompt Template\n",
    "\n",
    "This prompt helps the LLM take a big or complex question and break it down into 3‚Äì5 smaller sub-questions.  \n",
    "Each sub-question focuses on one part of the original ‚Äî great for improving retrieval and accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd593e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition\n",
    "# LLM prompt template to decompose user queries into multiple simpler sub-questions\n",
    "\n",
    "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Output (3 queries):\"\"\"\n",
    "\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f26d70",
   "metadata": {},
   "source": [
    "## Decomposition Query Test Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eb34ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. What is the standard warranty period for smartphones from major manufacturers?',\n",
       " '2. How can I check if my phone is still under warranty?',\n",
       " '3. What types of damages are typically covered under a smartphone warranty?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM\n",
    "open_ai_llm = LLMCall.azure_openai()\n",
    "\n",
    "generate_queries_decomposition = ( prompt_decomposition | open_ai_llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "\n",
    "# Run\n",
    "question = \"Is there a warranty on the phone?\"\n",
    "questions = generate_queries_decomposition.invoke({\"question\":question})\n",
    "questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a9920",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e55e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù Define the custom prompt template used in the Output for each decomposition query\n",
    "\n",
    "rag_template = \"\"\"\n",
    "You are a customer service agent for a apple mobile company.\n",
    "Customer Query: \\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "You have been given the following information about the context.\n",
    "Context: \\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
    "\n",
    "The answer should be based on the context provided.\n",
    "Your task is to answer the customer question based on the context provided. If the question is not related to the context, please say \"I don't know or Do Not Answer it just say please ask me question related to Apple Mobiles only\".\n",
    "Do not make up any information or provide any personal opinions or experiences.\n",
    "Please answer in a friendly and professional manner.\n",
    "\"\"\"\n",
    "\n",
    "prompt_rag_template = PromptTemplate.from_template(rag_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c5821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù Define the custom prompt template used in the final RAG stage\n",
    "final_template = \"\"\"\n",
    "\n",
    "You are a customer service agent for a apple mobile company.\n",
    "Customer Query: {question}\n",
    "\n",
    "You have been given the following set of Q+A pairs use the Answers as the context.\n",
    "Context: {context}\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
    "\n",
    "Answer:\n",
    "\n",
    "The answer should be based on the context provided.\n",
    "Your task is to answer the customer question based on the context provided. If the question is not related to the context, please say \"I don't know or Do Not Answer it just say please ask me question related to Apple Mobiles only\".\n",
    "Do not make up any information or provide any personal opinions or experiences.\n",
    "Please answer in a friendly and professional manner.\n",
    "\"\"\"\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_template(final_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8678b7f7",
   "metadata": {},
   "source": [
    "## üîÅ RAG Execution Over Decomposed Queries\n",
    "\n",
    "This function takes a complex user question, breaks it into sub-questions using a query decomposition chain, and then performs **RAG (Retrieve + Generate)** on each sub-question individually.\n",
    "\n",
    "### What it does:\n",
    "1. Generates sub-questions from the original query\n",
    "2. Retrieves relevant documents for each sub-question using a retriever\n",
    "3. Passes each sub-question and its context to the LLM to generate an answer\n",
    "4. Returns all generated answers along with the sub-questions\n",
    "\n",
    "This helps handle long or multi-topic questions by **splitting and answering them separately**, which improves relevance and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c2c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_rag(question,prompt_rag,sub_question_generator_chain,llm,retriever):\n",
    "    \"\"\"RAG on each sub-question\"\"\"\n",
    "    \n",
    "    # Step 1: Use the LLM to generate sub-questions from the main question\n",
    "    sub_questions = sub_question_generator_chain.invoke({\"question\":question})\n",
    "    \n",
    "    # Step 2: Initialize a list to store answers from each RAG chain results\n",
    "    rag_results = []\n",
    "    \n",
    "    for sub_question in sub_questions:\n",
    "        \n",
    "        # Step 3: Retrieve chunks relevant to the sub-question\n",
    "        retrieved_docs = retriever.get_relevant_documents(sub_question)\n",
    "        \n",
    "        # Step 4: Run prompt ‚Üí LLM ‚Üí parse to get answer\n",
    "        # Use retrieved documents and sub-question in RAG chain\n",
    "        answer = (prompt_rag | llm | StrOutputParser()).invoke({\"context\": retrieved_docs, \n",
    "                                                                \"question\": sub_question})\n",
    "        \n",
    "        # Step 5: Append the result to our answer list\n",
    "        rag_results.append(answer)\n",
    "    \n",
    "    return rag_results,sub_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8109206c",
   "metadata": {},
   "source": [
    "## üìù Format Q&A Results for Display\n",
    "\n",
    "This helper function takes in a list of sub-questions and their answers, and formats them into a readable block of text.\n",
    "\n",
    "It numbers each question and answer pair for easy review.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "453c7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_qa_pairs(questions, answers):\n",
    "    \"\"\"Format Q and A pairs\"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    \n",
    "    # Enumerate over each (question, answer) pair\n",
    "    for i, (question, answer) in enumerate(zip(questions, answers), start=1):\n",
    "        # Format the pair and append to the final string\n",
    "        formatted_string += f\"Question {i}: {question}\\nAnswer {i}: {answer}\\n\\n\"\n",
    "    \n",
    "    # Remove trailing newline and return\n",
    "    return formatted_string.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8837c1",
   "metadata": {},
   "source": [
    "## ‚òÅÔ∏è Using Azure OpenAI for Embeddings & Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece4b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_embeddings = Embeddings.azure_openai()\n",
    "\n",
    "vectorstore_openai = FAISS.from_documents(\n",
    "    texts,\n",
    "    open_ai_embeddings\n",
    ")\n",
    "\n",
    "azure_retriever = vectorstore_openai.as_retriever()\n",
    "\n",
    "# ü§ñ Initialize Azure OpenAI Chat Model (LLM)\n",
    "\n",
    "open_ai_llm = LLMCall.azure_openai()\n",
    "\n",
    "generate_queries_decomposition = ( prompt_decomposition | open_ai_llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "\n",
    "# Wrap the retrieval and RAG process in a RunnableLambda for integration into a chain\n",
    "answers, questions = retrieve_and_rag(question, prompt_rag_template, generate_queries_decomposition, open_ai_llm, azure_retriever)\n",
    "\n",
    "context = format_qa_pairs(questions, answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f930de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rag_chain = (\n",
    "    final_prompt\n",
    "    | open_ai_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "ans = final_rag_chain.invoke({\"context\":context,\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df56574c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, there is a warranty on the phone. Typically, smartphones, including Apple devices, come with a one-year limited warranty that covers defects in materials and workmanship. This warranty does not cover normal wear and tear or damage caused by accidents or abuse. If you have any further questions or need assistance regarding your Apple mobile, feel free to ask!'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b067f59",
   "metadata": {},
   "source": [
    "## ü§ó Using Hugging Face for Embeddings & Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_embeddings = Embeddings.huggingface()\n",
    "\n",
    "vectorstore_hf = FAISS.from_documents(\n",
    "    texts,\n",
    "    huggingface_embeddings)\n",
    "\n",
    "retriever_hf = vectorstore_hf.as_retriever()\n",
    "\n",
    "huggingface_llm = LLMCall.huggingface()\n",
    "\n",
    "generate_queries_decomposition = ( prompt_decomposition | huggingface_llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "\n",
    "# Wrap the retrieval and RAG process in a RunnableLambda for integration into a chain\n",
    "answers, questions = retrieve_and_rag(question, prompt_rag_template, generate_queries_decomposition, huggingface_llm, retriever_hf)\n",
    "\n",
    "context = format_qa_pairs(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff38dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rag_chain = (\n",
    "    final_prompt\n",
    "    | huggingface_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "ans = final_rag_chain.invoke({\"context\":context,\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a03f9b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, there is a warranty on the phone. Typically, smartphones, including Apple devices, come with a one-year limited warranty that covers defects in materials and workmanship. This warranty does not cover normal wear and tear or damage caused by accidents or abuse. If you have any further questions or need assistance regarding your Apple mobile, feel free to ask!'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909e775",
   "metadata": {},
   "source": [
    "## ü¶ô Using Ollama for Local LLM Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04906033",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_llm = LLMCall.chat_ollama()\n",
    "\n",
    "vectorstore_ollama = FAISS.from_documents(\n",
    "    texts,\n",
    "    huggingface_embeddings)\n",
    "\n",
    "retriever_ollama = vectorstore_ollama.as_retriever()\n",
    "\n",
    "generate_queries_decomposition = ( prompt_decomposition | ollama_llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "\n",
    "# Wrap the retrieval and RAG process in a RunnableLambda for integration into a chain\n",
    "answers, questions = retrieve_and_rag(question, prompt_rag_template, generate_queries_decomposition, ollama_llm, retriever_ollama)\n",
    "context = format_qa_pairs(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cc09ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rag_chain = (\n",
    "    final_prompt\n",
    "    | ollama_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "ans = final_rag_chain.invoke({\"context\":context,\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9243b410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, there is a warranty on the phone. Typically, smartphones, including Apple devices, come with a one-year limited warranty that covers defects in materials and workmanship. This warranty does not cover normal wear and tear or damage caused by accidents or abuse. If you have any further questions or need assistance regarding your Apple mobile, feel free to ask!'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a55a3a2",
   "metadata": {},
   "source": [
    "## ‚ö° Using Groq Inference API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2f61852",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_llm = LLMCall.chat_groq()\n",
    "\n",
    "vectorstore_groq = FAISS.from_documents(\n",
    "    texts,\n",
    "    open_ai_embeddings)\n",
    "\n",
    "retriever_groq = vectorstore_groq.as_retriever()\n",
    "\n",
    "generate_queries_decomposition = ( prompt_decomposition | groq_llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "\n",
    "# Wrap the retrieval and RAG process in a RunnableLambda for integration into a chain\n",
    "answers, questions = retrieve_and_rag(question, prompt_rag_template, generate_queries_decomposition, groq_llm, retriever_groq)\n",
    "context = format_qa_pairs(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f75376b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rag_chain = (\n",
    "    final_prompt\n",
    "    | groq_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "ans = final_rag_chain.invoke({\"context\":context,\"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af6b211a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, there is a warranty on the phone. The standard warranty period offered by Apple, the phone's manufacturer, is one year from the date of original retail purchase. This warranty covers defects in materials and workmanship, but it does not cover normal wear and tear or damage caused by accident or abuse. If you'd like to know more about what's covered under the warranty or how to file a claim, I'd be happy to help with that as well.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd615596",
   "metadata": {},
   "source": [
    "<!-- Font Awesome CDN (Add in <head> if not already included) -->\n",
    "<link\n",
    "  rel=\"stylesheet\" \n",
    "  href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css\"\n",
    "/>\n",
    "\n",
    "<!-- Social Footer Section -->\n",
    "<div style=\"\n",
    "  background-color:rgb(199, 195, 195);\n",
    "  padding: 40px 30px;\n",
    "  border-radius: 20px;\n",
    "  box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
    "  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "  font-size: 18px;\n",
    "  max-width: 900px;\n",
    "  margin: 60px auto 30px;\n",
    "  text-align: center;\n",
    "  color: #444;\n",
    "\">\n",
    "<!-- End of Notebook Note -->\n",
    "  <h2 style=\"margin-bottom: 10px;\">üìò End of Notebook</h2>\n",
    "  <p style=\"color: #666; font-size: 14px;\">\n",
    "    Thank you for exploring! Feel free to connect via the links below.\n",
    "  </p>\n",
    "\n",
    "  <!-- Social Icons -->\n",
    "<div style=\"\n",
    "  display: flex;\n",
    "  gap: 25px;\n",
    "  align-items: center;\n",
    "  flex-wrap: wrap;\n",
    "  justify-content: center;\n",
    "  margin-bottom: 25px;\n",
    "\">\n",
    "  <!-- LinkedIn -->\n",
    "  <a href=\"https://www.linkedin.com/in/ChiragB254\" target=\"_blank\" style=\"text-decoration: none; color: #0077b5;\">\n",
    "    <i class=\"fab fa-linkedin fa-lg\"></i> LinkedIn\n",
    "  </a>\n",
    "\n",
    "  <!-- GitHub -->\n",
    "  <a href=\"https://github.com/ChiragB254\" target=\"_blank\" style=\"text-decoration: none; color: #333;\">\n",
    "    <i class=\"fab fa-github fa-lg\"></i> GitHub\n",
    "  </a>\n",
    "\n",
    "  <!-- Instagram -->\n",
    "  <a href=\"https://www.instagram.com/data.scientist_chirag\" target=\"_blank\" style=\"text-decoration: none; color: #E1306C;\">\n",
    "    <i class=\"fab fa-instagram fa-lg\"></i> Instagram\n",
    "  </a>\n",
    "\n",
    "  <!-- Email -->\n",
    "  <a href=\"mailto:devchirag27@gmail.com\" style=\"text-decoration: none; color: #D44638;\">\n",
    "    <i class=\"fas fa-envelope fa-lg\"></i> Email\n",
    "  </a>\n",
    "\n",
    "  <!-- X (Twitter) -->\n",
    "  <a href=\"https://x.com/ChiragB254\" target=\"_blank\" style=\"text-decoration: none; color: #000;\">\n",
    "    <i class=\"fab fa-x-twitter fa-lg\"></i> X.com\n",
    "  </a>\n",
    "  </div>\n",
    "\n",
    "  <p style=\"font-size: 13px; color: black; font-style: italic; margin-top: 8px;\">\n",
    "    <strong>Made with ‚ù§Ô∏è by Chirag Bansal</strong>\n",
    "  </p>\n",
    "</div>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
