{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bc2504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from llm_call import LLMCall\n",
    "from embeddings import Embeddings\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ed422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chirag/miniconda3/envs/LLMs-env/lib/python3.10/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "# Load PDF and split it into chunks\n",
    "pdf_file = 'sample.pdf'\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 200\n",
    "\n",
    "loader = PyPDFLoader(pdf_file)\n",
    "documents = loader.load()\n",
    "\n",
    "# Split the document into manageable chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    ")\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb8aecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.3 (Macintosh)', 'creationdate': '2024-06-18T14:09:48-07:00', 'moddate': '2024-06-18T14:10:14-07:00', 'trapped': '/False', 'source': 'sample.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='Before using iPhone, review the iPhone User Guide  at  \\nsupport.apple.com/guide/iphone .\\nSafety and Handling\\nSee ‚ÄúSafety, handling, and support‚Äù in the iPhone  \\nUser Guide .\\nExposure to Radio Frequency\\nOn iPhone, go to Settings > General > Legal &  \\nRegulatory > RF Exposure. Or go to apple.com/  \\nlegal/rfexposure .\\nBattery and Charging\\nAn iPhone battery should only be repaired by a trained \\ntechnician to avoid battery damage, which could cause \\noverheating, fire, or injury. Batteries should be recycled \\nor disposed of separately from household waste and \\naccording to local environmental laws and guidelines. For \\ninformation about Apple lithium-ion batteries and battery \\nservice and recycling, go to apple.com/batteries/service-\\nand-recycling . For information about charging, see \\n‚ÄúImportant safety information‚Äù in the iPhone User Guide.\\nLasers\\nThe proximity sensor, the TrueDepth camera system, \\nand the LiDAR Scanner contain one or more lasers.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef5c06a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b0ad2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-query template\n",
    "multi_query_template = \"\"\"\n",
    "\n",
    "You are a question(query) generator. You can create multiple questions similar with multiple prespective to the given question with the same meaning.\n",
    "By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Please generate 5 questions similar to the given question.\n",
    "Make sure to use different words and phrases to express the same idea.\n",
    "The questions should be clear and concise.\n",
    "The questions should be grammatically correct and easy to understand.\n",
    "The questions should be in English.\n",
    "Provide these alternative questions separated by newlines.\n",
    "\n",
    "The question is: {question}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f27bbc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_query_prompt = ChatPromptTemplate.from_messages(    [\n",
    "\t(\"system\", \"You are a helpful assistant.\"),\n",
    "\t(\"human\", multi_query_template),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23a45be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d49bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom prompt template for generation\n",
    "\n",
    "rag_template = \"\"\"\n",
    "You are a customer service agent for a apple mobile company. \n",
    "You have been given the following information about the customer question and the context.\n",
    "Customer Query: {question}\n",
    "Context: {context}\n",
    "\n",
    "Answer: \n",
    "The answer should be based on the context provided.\n",
    "Your task is to answer the customer question based on the context provided. If the question is not related to the context, please say \"I don't know or Do Not Answer it just say please ask me question related to Apple Mobiles only\".\n",
    "Do not make up any information or provide any personal opinions or experiences.\n",
    "Please answer in a friendly and professional manner.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e4b3bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\nYou are a customer service agent for a apple mobile company. \\nYou have been given the following information about the customer question and the context.\\nCustomer Query: {question}\\nContext: {context}\\n\\nAnswer: \\nThe answer should be based on the context provided.\\nYour task is to answer the customer question based on the context provided. If the question is not related to the context, please say \"I don\\'t know or Do Not Answer it just say please ask me question related to Apple Mobiles only\".\\nDo not make up any information or provide any personal opinions or experiences.\\nPlease answer in a friendly and professional manner.\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "rag_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "\t(\"system\", \"You are a helpful assistant.\"),\n",
    "\t(\"human\", rag_template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(rag_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61db220",
   "metadata": {},
   "source": [
    "Using Azure OpenAI Embeddings and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df9c4089",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_embeddings = Embeddings.azure_openai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f85f2863",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(\n",
    "    texts,\n",
    "    open_ai_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f08b3444",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a90be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_llm = LLMCall.azure_openai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15ee4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Generate the Multiple questions based on given question to retrive documents in a better way.\n",
    "multi_query_chain = m_query_prompt| open_ai_llm | StrOutputParser() | (lambda x: x.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c3cbfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/39/wh_jffd90vv2lczbpfngvr200000gn/T/ipykernel_31123/170002541.py:10: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  return [loads(doc) for doc in unique_docs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Testing/ Showing if we are getting our questions of not and we are checking the length of unique chunks from it.\n",
    "'''\n",
    "\n",
    "# Retrieve\n",
    "question = \"Is there a warranty on the phone?\"\n",
    "multi_query_retrieval_chain = multi_query_chain | retriever.map() | get_unique_union\n",
    "docs = multi_query_retrieval_chain.invoke({\"question\":question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "637693c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rag_chain = (\n",
    "    {\"context\": multi_query_retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | rag_prompt\n",
    "    | open_ai_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7f038a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Answer: Yes, there is a warranty on the phone. Apple offers a One-Year Limited Warranty that covers defects in materials and workmanship for one year from the date of original retail purchase. However, this warranty does not cover normal wear and tear or damage caused by accident or abuse. If you need service, you can call Apple or visit an Apple Store or an Apple Authorized Service Provider. For more detailed information, you can visit apple.com/legal/warranty.\n"
     ]
    }
   ],
   "source": [
    "response = final_rag_chain.invoke({\"question\":question})\n",
    "\n",
    "print('üì¶ Answer:', response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25385c7f",
   "metadata": {},
   "source": [
    "Using HuggingFace Model and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "851c7870",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_embeddings = Embeddings.huggingface()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b37287b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(\n",
    "    texts,\n",
    "    huggingface_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62cf5b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4fa917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Same Multi-query template as above \n",
    "# but as we mentioned above but here we are using huggingface embeddings and huggingface models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5c223a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface_llm = LLMCall.huggingface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d02fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_query_chain = m_query_prompt | open_ai_llm | StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",
    "multi_query_retrieval_chain = multi_query_chain | retriever.map() | get_unique_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6266f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rag_chain = (\n",
    "    {\"context\": multi_query_retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | rag_prompt\n",
    "    | open_ai_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# huggingface_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b29a084b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Answer: Yes, there is a warranty on the phone. Apple offers a one-year limited warranty that covers defects in materials and workmanship for the included hardware product and accessories from the date of original retail purchase. However, this warranty does not cover normal wear and tear or damage caused by accident or abuse. If you need to obtain service, you can call Apple or visit an Apple Store or an Apple Authorized Service Provider. For more detailed information, you can visit apple.com/legal/warranty. If you have any further questions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "response = final_rag_chain.invoke({\"question\":question})\n",
    "\n",
    "print('üì¶ Answer:', response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068e0a48",
   "metadata": {},
   "source": [
    "Using Ollama\n",
    "\n",
    "> We are using the same huggingFace embeddings for Ollama to but instead of using model from huggingface or OpenAI, we use our locally downloaded model through `Ollama` which is llama3.2 in this example. If you want to download or run this example with any other model please check the ollama model library and download it using `ollama run <model name>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf767166",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_llm = LLMCall.chat_ollama()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24978fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_query_chain = m_query_prompt | ollama_llm | StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",
    "multi_query_retrieval_chain = multi_query_chain | retriever.map() | get_unique_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc7138d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rag_chain = (\n",
    "    {\"context\": multi_query_retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | rag_prompt\n",
    "    | ollama_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a2503c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Answer: Yes, there is a warranty on the phone. According to the information provided, Apple offers a one-year limited warranty on the hardware product and accessories against defects in materials and workmanship from the date of original retail purchase. You can find more detailed information on obtaining service and the full terms of the warranty at apple.com/legal/warranty and support.apple.com.\n"
     ]
    }
   ],
   "source": [
    "response = final_rag_chain.invoke({\"question\":question})\n",
    "\n",
    "print('üì¶ Answer:', response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6befae8",
   "metadata": {},
   "source": [
    "Using Groq Infrance API \n",
    "\n",
    "> In this example we are using groq infrance api key to harness the power of fast infrance enabled api model from groq. In my case I am using `llama-3.3-70b-versatile` aka `lamma-3.3`. But again if you want to use any other model use can pass the name of model in the functiin which I am calling here or you can also change it in `llm_call.py` file under chat_groq function of class `LLMClaa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e210136",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_llm = LLMCall.chat_groq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2319ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_query_chain = m_query_prompt | groq_llm | StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",
    "multi_query_retrieval_chain = multi_query_chain | retriever.map() | get_unique_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "615e774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rag_chain = (\n",
    "    {\"context\": multi_query_retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | rag_prompt\n",
    "    | groq_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04c8a78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Answer: Yes, there is a warranty on the phone. According to the Apple One-Year Limited Warranty Summary, Apple warrants the included hardware product and accessories against defects in materials and workmanship for one year from the date of original retail purchase. You can find more detailed information on obtaining service at apple.com/legal/warranty and support.apple.com.\n"
     ]
    }
   ],
   "source": [
    "response = final_rag_chain.invoke({\"question\":question})\n",
    "\n",
    "print('üì¶ Answer:', response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3db2a5",
   "metadata": {},
   "source": [
    "<!-- Font Awesome CDN (Add in <head> if not already included) -->\n",
    "<link\n",
    "  rel=\"stylesheet\" \n",
    "  href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css\"\n",
    "/>\n",
    "\n",
    "<!-- Social Footer Section -->\n",
    "<div style=\"\n",
    "  background-color:rgb(199, 195, 195);\n",
    "  padding: 40px 30px;\n",
    "  border-radius: 20px;\n",
    "  box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
    "  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "  font-size: 18px;\n",
    "  max-width: 900px;\n",
    "  margin: 60px auto 30px;\n",
    "  text-align: center;\n",
    "  color: #444;\n",
    "\">\n",
    "<!-- End of Notebook Note -->\n",
    "  <h2 style=\"margin-bottom: 10px;\">üìò End of Notebook</h2>\n",
    "  <p style=\"color: #666; font-size: 14px;\">\n",
    "    Thank you for exploring! Feel free to connect via the links below.\n",
    "  </p>\n",
    "\n",
    "  <!-- Social Icons -->\n",
    "<div style=\"\n",
    "  display: flex;\n",
    "  gap: 25px;\n",
    "  align-items: center;\n",
    "  flex-wrap: wrap;\n",
    "  justify-content: center;\n",
    "  margin-bottom: 25px;\n",
    "\">\n",
    "  <!-- LinkedIn -->\n",
    "  <a href=\"https://www.linkedin.com/in/ChiragB254\" target=\"_blank\" style=\"text-decoration: none; color: #0077b5;\">\n",
    "    <i class=\"fab fa-linkedin fa-lg\"></i> LinkedIn\n",
    "  </a>\n",
    "\n",
    "  <!-- GitHub -->\n",
    "  <a href=\"https://github.com/ChiragB254\" target=\"_blank\" style=\"text-decoration: none; color: #333;\">\n",
    "    <i class=\"fab fa-github fa-lg\"></i> GitHub\n",
    "  </a>\n",
    "\n",
    "  <!-- Instagram -->\n",
    "  <a href=\"https://www.instagram.com/data.scientist_chirag\" target=\"_blank\" style=\"text-decoration: none; color: #E1306C;\">\n",
    "    <i class=\"fab fa-instagram fa-lg\"></i> Instagram\n",
    "  </a>\n",
    "\n",
    "  <!-- Email -->\n",
    "  <a href=\"mailto:devchirag27@gmail.com\" style=\"text-decoration: none; color: #D44638;\">\n",
    "    <i class=\"fas fa-envelope fa-lg\"></i> Email\n",
    "  </a>\n",
    "\n",
    "  <!-- X (Twitter) -->\n",
    "  <a href=\"https://x.com/ChiragB254\" target=\"_blank\" style=\"text-decoration: none; color: #000;\">\n",
    "    <i class=\"fab fa-x-twitter fa-lg\"></i> X.com\n",
    "  </a>\n",
    "  </div>\n",
    "\n",
    "  <p style=\"font-size: 13px; color: black; font-style: italic; margin-top: 8px;\">\n",
    "    <strong>Made with ‚ù§Ô∏è by Chirag Bansal</strong>\n",
    "  </p>\n",
    "</div>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
