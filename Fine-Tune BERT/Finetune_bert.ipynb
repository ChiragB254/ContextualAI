{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine Tune BERT model for Text Classification (Spam or Non-Spam)**\n",
        "\n",
        "\n",
        "> This approach involves fine-tuning a pre-trained BERT model by adding a new classification layer on top while keeping the pre-trained weights frozen. The added layer is a fully connected layer that maps BERT's output embeddings to the two target classes: \"Spam\" and \"Non-Spam.\"  \n",
        "\n",
        "> By freezing the pre-trained weights, the model retains its rich linguistic understanding gained from training on a large corpus, while the newly added layer learns task-specific patterns from the labeled dataset. This method is computationally efficient and minimizes the risk of overfitting, making it ideal for scenarios with limited data or resources.  \n",
        "\n",
        "> The resulting model effectively classifies text messages or emails as spam or non-spam with high accuracy and robustness.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3AdmYShqKkV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Transformers Library**\n",
        "\n",
        "> Installing Huggingfaceâ€™s transformers library. This library lets you import a wide range of transformer-based pre-trained models\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "!pip install transformers\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6-lLHQrsLxZv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrtmrTteFBT3",
        "outputId": "a9af77e3-7772-45dc-d3e5-f02364a071b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries**"
      ],
      "metadata": {
        "id": "0qQmGPNTMBBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "pyfM3r5uPBF1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Dataset**\n",
        "\n",
        "> Download spam dataset from this [Link](https://raw.githubusercontent.com/ChiragB254/ContextualAI/refs/heads/main/Fine-Tune%20BERT/spamdata.txt) or from my directly from my [Github Repo ](https://github.com/ChiragB254/ContextualAI/tree/main/Fine-Tune%20BERT)and upload it into your Colab notebook runtime."
      ],
      "metadata": {
        "id": "n7rFISI6MMuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/spamdata.txt\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tWIR0Z4ZPJ6M",
        "outputId": "bbd7f0e2-7346-4d00-a6e7-dc336aab5496"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-360f2f8f-3223-4272-9940-6cfad2a28650\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-360f2f8f-3223-4272-9940-6cfad2a28650')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-360f2f8f-3223-4272-9940-6cfad2a28650 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-360f2f8f-3223-4272-9940-6cfad2a28650');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7d9d30d9-f75c-4c30-a76b-ebde187d3d34\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d9d30d9-f75c-4c30-a76b-ebde187d3d34')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7d9d30d9-f75c-4c30-a76b-ebde187d3d34 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"Did u download the fring app?\",\n          \"Pass dis to all ur contacts n see wat u get! Red;i'm in luv wid u. Blue;u put a smile on my face. Purple;u r realy hot. Pink;u r so swt. Orange;i thnk i lyk u. Green;i realy wana go out wid u. Yelow;i wnt u bck. Black;i'm jealous of u. Brown;i miss you Nw plz giv me one color\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split this dataset into three sets â€“ train, validation, and test**"
      ],
      "metadata": {
        "id": "Y-9JAeqoM0l9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split train dataset into train, validation and test sets\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'],\n",
        "                                                                    random_state=2018,\n",
        "                                                                    test_size=0.3,\n",
        "                                                                    stratify=df['label'])\n",
        "\n",
        "\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
        "                                                                random_state=2018,\n",
        "                                                                test_size=0.5,\n",
        "                                                                stratify=temp_labels)"
      ],
      "metadata": {
        "id": "lFf8X6PIPrkY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import BERT Model and BERT Tokenizer**\n",
        "\n",
        "> We will import the BERT-base model that has 110 million parameters not BERT large with 340 million param one"
      ],
      "metadata": {
        "id": "7Br6pmAXM88V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4al8TDtP1HR",
        "outputId": "997d1d40-3d6a-4808-e4a0-1564a52694d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenize the Sentences**\n",
        "\n",
        "> But before tokenization we are checking what is the most comman length and the length which cover most of the text in the dataset so that we can use padding according to that not by max length of the message of the data"
      ],
      "metadata": {
        "id": "4eh-2hKkNSMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "9PxIKzyJP6OD",
        "outputId": "6fc30815-9c06-4d09-9caf-f5af2d6e69a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1SmfA_YQAY5",
        "outputId": "cd46ddda-a943-4149-f1c3-bbc493941bbd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convert the integer sequences to tensors**"
      ],
      "metadata": {
        "id": "lQxLgKTfOMQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## convert lists to tensors\n",
        "\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "metadata": {
        "id": "_wdgKJN8QF-4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataloaders Creation**\n",
        "\n",
        "> We will create dataloaders for both train and validation set. These dataloaders will pass batches of train data and validation data as input to the model during the training phase."
      ],
      "metadata": {
        "id": "EfriDashOUcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "e04ObxFHQJd4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Model Architecture**\n",
        "\n",
        "> ðŸ”¥ Most important first freeze all the layers of the model before fine-tuning it.\n",
        "\n"
      ],
      "metadata": {
        "id": "aC4HdwTiOjPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "UQ60Z62qQTWo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define our model architecture**"
      ],
      "metadata": {
        "id": "ZvWLJk7GO7a4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "\n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert\n",
        "\n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "\n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model\n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "\n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "\n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "tGk-GGorQYCK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "EJaSty5kQdt7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> # **Use AdamW as our optimizer, an improved version of the Adam optimizer**"
      ],
      "metadata": {
        "id": "GLkTRaU8PE0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 1e-5)          # learning rate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k7yYG7mQge4",
        "outputId": "16edf97a-1483-4a14-c090-414d68bbc352"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Class Imbalance handling**\n",
        "\n",
        "> There is a class imbalance in our dataset. The majority of the observations are not spam. So, we will first compute class weights for the labels in the train set and then pass these weights to the loss function so that it takes care of the class imbalance."
      ],
      "metadata": {
        "id": "eYHkc-EAPVyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "# Pass arguments as keyword arguments\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "\n",
        "print(\"Class Weights:\",class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1I1_DZlQljv",
        "outputId": "9e24549d-ffae-44b7-d3a3-72dda48294d8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: [0.57743559 3.72848948]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting list of class weights to a tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# push to GPU\n",
        "weights = weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights)\n",
        "\n",
        "# number of training epochs\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "MenGIl37Qyzc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine-Tune BERT**"
      ],
      "metadata": {
        "id": "gK7VPH-HPlFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## Function to train the model"
      ],
      "metadata": {
        "id": "tqMLypJCPuEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "\n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "\n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # print(sent_id)\n",
        "    # print(mask.shape)\n",
        "    # print(labels.shape)\n",
        "\n",
        "    # clear previously calculated gradients\n",
        "    model.zero_grad()\n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds\n"
      ],
      "metadata": {
        "id": "B3cczrXcQ8xA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## Function to evaluate the model"
      ],
      "metadata": {
        "id": "qKzpdmLMPxOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "\n",
        "  print(\"\\nEvaluating...\")\n",
        "\n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "\n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "\n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "\n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "\n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader)\n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds\n"
      ],
      "metadata": {
        "id": "IsJWGDz0RB_T"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Starting fine-tuning of the model**"
      ],
      "metadata": {
        "id": "JGwSlffTP80k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "\n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "\n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVnWHzqvRG_i",
        "outputId": "56b3975c-f62d-4d51-f67e-73475bff518d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.569\n",
            "Validation Loss: 0.548\n",
            "\n",
            " Epoch 2 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.551\n",
            "Validation Loss: 0.522\n",
            "\n",
            " Epoch 3 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.527\n",
            "Validation Loss: 0.500\n",
            "\n",
            " Epoch 4 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.512\n",
            "Validation Loss: 0.484\n",
            "\n",
            " Epoch 5 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.492\n",
            "Validation Loss: 0.464\n",
            "\n",
            " Epoch 6 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.478\n",
            "Validation Loss: 0.445\n",
            "\n",
            " Epoch 7 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.458\n",
            "Validation Loss: 0.432\n",
            "\n",
            " Epoch 8 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.449\n",
            "Validation Loss: 0.414\n",
            "\n",
            " Epoch 9 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.432\n",
            "Validation Loss: 0.403\n",
            "\n",
            " Epoch 10 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.427\n",
            "Validation Loss: 0.390\n",
            "\n",
            " Epoch 11 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.404\n",
            "Validation Loss: 0.377\n",
            "\n",
            " Epoch 12 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.399\n",
            "Validation Loss: 0.373\n",
            "\n",
            " Epoch 13 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.393\n",
            "Validation Loss: 0.357\n",
            "\n",
            " Epoch 14 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.377\n",
            "Validation Loss: 0.354\n",
            "\n",
            " Epoch 15 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.372\n",
            "Validation Loss: 0.341\n",
            "\n",
            " Epoch 16 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.358\n",
            "Validation Loss: 0.331\n",
            "\n",
            " Epoch 17 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.343\n",
            "Validation Loss: 0.328\n",
            "\n",
            " Epoch 18 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.351\n",
            "Validation Loss: 0.319\n",
            "\n",
            " Epoch 19 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.332\n",
            "Validation Loss: 0.312\n",
            "\n",
            " Epoch 20 / 20\n",
            "  Batch    50  of    122.\n",
            "  Batch   100  of    122.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.330\n",
            "Validation Loss: 0.303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving the weights for future usage**"
      ],
      "metadata": {
        "id": "NcbzawYeQGlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkZehNa_RQVQ",
        "outputId": "93aca062-1b28-4d73-8710-2233923fd84e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-5a29cc8ec3f6>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(path))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Make Predictions**"
      ],
      "metadata": {
        "id": "_ZIZGs8JQX4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "wH6LzOeETxHV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## Modelâ€™s performance"
      ],
      "metadata": {
        "id": "xPGGHpzBQc-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF_Q3QS0T0Bh",
        "outputId": "c339c3a8-1dd9-4674-b43d-34010a7622d8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.90      0.94       724\n",
            "           1       0.57      0.90      0.70       112\n",
            "\n",
            "    accuracy                           0.90       836\n",
            "   macro avg       0.78      0.90      0.82       836\n",
            "weighted avg       0.93      0.90      0.91       836\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **User Friendly block**\n",
        "\n",
        "> A user friendly block to test with your own random message. This model still need some traing as you see I trained it only on 20 epochs and data was not too much *( not a large dataset)* so it might give you incorrect results."
      ],
      "metadata": {
        "id": "MQBMUqGtQl4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Display a friendly welcome message\n",
        "print(\"\\nWelcome to the Spam Detection System!\")\n",
        "print(\"This tool will help you identify if a message is spam or not.\\n\")\n",
        "\n",
        "# Infinite loop to allow multiple checks\n",
        "while True:\n",
        "    # Get user input\n",
        "    user_input = input(\"Enter your message (or type 'exit' to quit): \").strip()\n",
        "\n",
        "    # Exit condition\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"\\nThank you for using the Spam Detection System. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Check for empty input\n",
        "    if not user_input:\n",
        "        print(\"âš ï¸ Please enter a valid message!\")\n",
        "        continue\n",
        "\n",
        "    # Tokenize user input\n",
        "    tokens_user_input = tokenizer.batch_encode_plus(\n",
        "        [user_input],\n",
        "        max_length=25,\n",
        "        pad_to_max_length=True,\n",
        "        truncation=True\n",
        "    )\n",
        "    user_input_seq = torch.tensor(tokens_user_input['input_ids'])\n",
        "    user_input_mask = torch.tensor(tokens_user_input['attention_mask'])\n",
        "    print('\\n')\n",
        "\n",
        "    # Perform prediction\n",
        "    with torch.no_grad():\n",
        "        user_input_preds = model(user_input_seq.to(device), user_input_mask.to(device))\n",
        "        user_input_preds = user_input_preds.detach().cpu().numpy()\n",
        "        user_input_preds = np.argmax(user_input_preds, axis=1)\n",
        "        # Output the result\n",
        "        if user_input_preds == 0:\n",
        "            print(\"\\033[1mâœ… Your message is NOT SPAM.\\033[0m\\n\")\n",
        "        else:\n",
        "            print(\"\\033[1mðŸš¨ Your message is SPAM.\\033[0m\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Juy4Oxoda6z0",
        "outputId": "13a5d777-26ab-42c3-e998-c7ee5bf8d218"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Welcome to the Spam Detection System!\n",
            "This tool will help you identify if a message is spam or not.\n",
            "\n",
            "Enter your message (or type 'exit' to quit): Haha just kidding, papa needs drugs\n",
            "\n",
            "\n",
            "\u001b[1mâœ… Your message is NOT SPAM.\u001b[0m\n",
            "\n",
            "Enter your message (or type 'exit' to quit): SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\n",
            "\n",
            "\n",
            "\u001b[1mðŸš¨ Your message is SPAM.\u001b[0m\n",
            "\n",
            "Enter your message (or type 'exit' to quit): Exit\n",
            "\n",
            "Thank you for using the Spam Detection System. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\\begin{array}{|c|}\n",
        "\\hline\n",
        "\\textbf\\\\\n",
        "\\textbf{ Thank You} \\\\\n",
        "\\text{ } \\\\\n",
        "\\textbf{**** End Of Notebook ****} \\\\\n",
        "\\text{ } \\\\\n",
        "\\hline\n",
        "\\end{array}\n"
      ],
      "metadata": {
        "id": "_nzSW32HRfae"
      }
    }
  ]
}